# â­ REWARD FUNCTION V2 - ALIGNÃ‰E BUSINESS

**Date :** 21 Octobre 2025  
**Objectif :** Aligner reward avec objectifs business  
**Statut :** âœ… **MODIFIÃ‰ - PrÃªt pour rÃ©entraÃ®nement**

---

## ğŸ¯ Objectifs Business

```
1. âœ… Maximiser le nombre d'assignments
2. âœ… Minimiser la distance parcourue
3. âœ… ContrÃ´ler les late pickups (<40% acceptable)
4. âœ… Minimiser les cancellations
```

---

## ğŸ“Š Changements AppliquÃ©s

### Fichier ModifiÃ©

**backend/services/rl/dispatch_env.py** (lignes 349-426)

---

### Comparaison V1 vs V2

| Composante               | V1 (Conservateur) | V2 (AlignÃ© Business) | Changement   |
| ------------------------ | ----------------- | -------------------- | ------------ |
| **Assignment rÃ©ussi**    | +50               | **+100**             | +100% â­     |
| **Late pickup**          | -100 max          | **-50 max**          | -50% â­      |
| **Cancellation**         | -200 max          | **-60 max**          | -70% â­      |
| **Distance penalty**     | Implicite         | **-distance/20**     | Explicite â­ |
| **Bonus distance < 5km** | +10 Ã  +20         | +10 Ã  +20            | InchangÃ©     |
| **Bonus prioritÃ©**       | +20 max           | +20 max              | InchangÃ©     |
| **Bonus rapiditÃ©**       | +15               | +15                  | InchangÃ©     |

---

## ğŸ’¡ Rationale des Changements

### 1. Assignment Reward : +50 â†’ +100 â­

**ProblÃ¨me V1 :**

```
Assignment rÃ©ussi : +50
Cancellation      : -200
Ratio             : 1:4 (risque trop Ã©levÃ©)

â†’ Agent Ã©vite assignments risquÃ©s
â†’ Trop conservateur
â†’ Moins d'assignments (6.3 vs 7.5 baseline)
```

**Solution V2 :**

```
Assignment rÃ©ussi : +100 â­
Cancellation      : -60
Ratio             : 1:0.6 (risque acceptable)

â†’ Encourage assignments
â†’ Plus agressif
â†’ Plus d'assignments attendues
```

---

### 2. Late Pickup Penalty : -100 â†’ -50 â­

**ProblÃ¨me V1 :**

```
Late pickup : -100 (trÃ¨s pÃ©nalisant)

â†’ Agent refuse assignments risquÃ©s
â†’ PrÃ©fÃ¨re canceller que risquer retard
â†’ Taux late pickups trÃ¨s bas (36.9%) mais peu d'assignments
```

**Solution V2 :**

```
Late pickup : -50 â­ (modÃ©rÃ©)

â†’ TolÃ©rance retards acceptable (<40%)
â†’ Encourage prendre risques calculÃ©s
â†’ Plus d'assignments avec contrÃ´le late pickups
```

---

### 3. Cancellation Penalty : -200 â†’ -60 â­

**ProblÃ¨me V1 :**

```
Cancellation : -200 (Ã©norme pÃ©nalitÃ©)

â†’ Agent TERRIFI Ã‰ d'annuler
â†’ PrÃ©fÃ¨re ne rien faire que risquer annulation
â†’ Paralysie dÃ©cisionnelle
```

**Solution V2 :**

```
Cancellation : -60 â­ (raisonnable)

â†’ PÃ©nalitÃ© significative mais pas paralysante
â†’ Agent peut prendre risques
â†’ Ã‰quilibre assignments vs annulations
```

---

### 4. Distance Penalty : Ajout Explicite â­

**Ajout V2 :**

```python
reward -= distance / 20.0  # PÃ©nalitÃ© explicite distance
```

**Effet :**

```
5 km  â†’ -0.25 points
10 km â†’ -0.50 points
20 km â†’ -1.00 point
```

**Pourquoi :**

- Encourage proximitÃ©
- Mais pas trop pÃ©nalisant
- Maintient optimisation distance
- Compatible avec bonus distance < 5km

---

## ğŸ“ˆ Effets Attendus

### Comportement Agent V1 (Conservateur)

```
âœ… Distance optimale (-20%)
âŒ Trop peu d'assignments (6.3 vs 7.5)
âŒ Trop de cancellations
âš ï¸ Trop prudent
```

### Comportement Agent V2 Attendu (Ã‰quilibrÃ©)

```
âœ… Bon nombre d'assignments (7-8 attendu)
âœ… Distance toujours optimisÃ©e
âœ… Late pickups contrÃ´lÃ©s (<40%)
âœ… Moins de cancellations
âœ… Plus agressif mais intelligent
```

---

## ğŸ¯ Comparaison Ã‰quilibre Reward

### V1 : DÃ©sÃ©quilibrÃ©

```
Best case assignment:
  +50 (base) +20 (distance) +20 (prioritÃ©) +15 (rapide)
  = +105 max

Worst case cancellation:
  -200 (prioritÃ© max)
  = -200 max

Ratio: +105 vs -200 â†’ DÃ©sÃ©quilibrÃ© vers prudence
```

### V2 : Ã‰quilibrÃ© â­

```
Best case assignment:
  +100 (base) +20 (distance) +20 (prioritÃ©) +15 (rapide)
  = +155 max

Worst case cancellation:
  -60 (prioritÃ© max)
  = -60 max

Ratio: +155 vs -60 â†’ Ã‰quilibrÃ©, encourage action
```

**Agent sera plus confiant pour assigner !**

---

## ğŸš€ Prochaines Ã‰tapes

### Ã‰tape 1 : Test Rapide (5 min)

```bash
# Tester que l'environnement fonctionne
docker-compose exec api python scripts/rl/test_env_quick.py

# Devrait montrer rewards plus Ã©levÃ©s
```

---

### Ã‰tape 2 : RÃ©optimisation Optuna (2-3h)

```bash
docker-compose exec api python scripts/rl/tune_hyperparameters.py \
  --trials 50 \
  --episodes 200 \
  --study-name dqn_optimization_v2 \
  --output data/rl/optimal_config_v2.json
```

**Attendu :**

- Best reward : -400 Ã  -600 (vs -701.7 V1)
- AmÃ©lioration : +15-30% vs V1
- Plus d'assignments
- Distance toujours optimisÃ©e

---

### Ã‰tape 3 : RÃ©entraÃ®nement (2-3h)

```bash
# Utiliser config optimale V2
docker-compose exec api python scripts/rl/train_dqn.py \
  --episodes 1000 \
  --learning-rate <optimal_v2_lr> \
  --gamma <optimal_v2_gamma> \
  --batch-size <optimal_v2_batch> \
  --num-drivers 6 \
  --max-bookings 10
```

---

### Ã‰tape 4 : Ã‰valuation Finale

```bash
docker-compose exec api python scripts/rl/evaluate_agent.py \
  --model data/rl/models/dqn_best.pth \
  --episodes 100 \
  --compare-baseline \
  --num-drivers 6 \
  --max-bookings 10
```

**CritÃ¨res de succÃ¨s :**

```
âœ… Assignments > 7/Ã©pisode (vs 6.3 V1, 7.5 baseline)
âœ… Distance < 65 km/Ã©pisode (vs 59.9 V1, 75.2 baseline)
âœ… Late pickups < 40% (vs 36.9% V1, 38.3% baseline)
âœ… ComplÃ©tion > 40% (vs 34.8% V1, 44.8% baseline)
```

---

## ğŸ“Š PrÃ©dictions V2

### MÃ©triques Attendues

```
Assignments      : 7-8/Ã©pisode (+11-27% vs V1)
Distance         : 60-65 km (-13-18% vs baseline)
Late pickups     : 37-39% (-0.5 vs baseline, stable)
Taux complÃ©tion  : 40-45% (+5-10 pts vs V1)
Cancellations    : RÃ©duites significativement
```

### Reward Attendu

```
Training reward  : -400 Ã  -600 (vs -664.9 V1)
Best reward      : -300 Ã  -400 (vs -518.2 V1)
AmÃ©lioration V2  : +15-30% vs V1
AmÃ©lioration totale: +70-80% vs baseline originale
```

---

## âœ… Validation

### Checklist Modifications

- [x] Assignment reward augmentÃ© (+50 â†’ +100)
- [x] Late pickup penalty rÃ©duite (-100 â†’ -50)
- [x] Cancellation penalty rÃ©duite (-200 â†’ -60)
- [x] Distance penalty ajoutÃ©e explicitement (-d/20)
- [x] Documentation reward mise Ã  jour
- [x] 0 erreur linting

### Tests Ã  Lancer

```bash
# Test environnement
python scripts/rl/test_env_quick.py

# Tests unitaires
pytest tests/rl/test_dispatch_env.py -v

# Validation reward plus Ã©levÃ©s
```

---

## ğŸ† RÃ©sumÃ© Changements

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  âœ… REWARD FUNCTION V2 CRÃ‰Ã‰E                  â•‘
â•‘  â­ ASSIGNMENT: +50 â†’ +100 (+100%)            â•‘
â•‘  â­ LATE PICKUP: -100 â†’ -50 (-50%)            â•‘
â•‘  â­ CANCELLATION: -200 â†’ -60 (-70%)           â•‘
â•‘  â­ DISTANCE: PÃ©nalitÃ© explicite -d/20        â•‘
â•‘  âœ… ALIGNÃ‰E AVEC OBJECTIFS BUSINESS           â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

---

## ğŸ¯ Prochaine Action ImmÃ©diate

**Tester que Ã§a fonctionne :**

```bash
docker-compose exec api python scripts/rl/test_env_quick.py
```

**Puis lancer rÃ©optimisation :**

```bash
docker-compose exec api python scripts/rl/tune_hyperparameters.py \
  --trials 50 \
  --episodes 200 \
  --study-name dqn_optimization_v2 \
  --output data/rl/optimal_config_v2.json
```

**RÃ©sultat attendu :** Agent plus agressif, plus d'assignments, distance optimisÃ©e, meilleur Ã©quilibre global ! ğŸ¯

---

_Reward V2 crÃ©Ã©e le 21 octobre 2025_  
_AlignÃ©e avec objectifs business_ âœ…  
_PrÃªte pour rÃ©optimisation !_ ğŸš€
