# üìä √âvaluation Mod√®le Best (Episode 450) - R√©sultats

**Date** : 21 octobre 2025, 06:45  
**Mod√®le** : `data/rl/models/dqn_best.pth`  
**Episodes √©valu√©s** : 100  
**Configuration** : 3 drivers, 20 bookings, 8h simulation

---

## üî¥ **R√âSULTATS D√âCEVANTS**

### **M√©triques Principales**

| M√©trique            | **R√©sultat**          | **Baseline**    | **Delta**  | **Statut**             |
| ------------------- | --------------------- | --------------- | ---------- | ---------------------- |
| **Reward moyen**    | **-40.6**             | -48.9           | +17%       | ‚úÖ L√©g√®re am√©lioration |
| **Reward m√©dian**   | **+44.0**             | N/A             | -          | ‚úÖ Positif             |
| **Assignments**     | **15.3 / 20** (76.5%) | 17.8 / 20 (89%) | **-14%**   | ‚ùå R√©gression          |
| **Late pickups**    | **5.8**               | 7.3             | **-20.5%** | ‚úÖ Am√©lioration        |
| **Taux compl√©tion** | **28.3%**             | ~89%            | **-68%**   | ‚ùå Catastrophique      |
| **Cancellations**   | **39.1**              | ~2              | **+1855%** | ‚ùå Critique            |
| **Distance**        | 151.5 km              | N/A             | -          | -                      |

### **Variance**

| M√©trique              | Valeur            |
| --------------------- | ----------------- |
| **√âcart-type reward** | ¬±456.2            |
| **Range reward**      | [-1531.1, +737.1] |

**‚Üí Variance TR√àS √©lev√©e = agent instable**

---

## üîç **ANALYSE D√âTAILL√âE**

### **Points Positifs** ‚úÖ

1. **Late pickups r√©duits** : 5.8 vs 7.3 (-20.5%)
2. **Reward m√©dian positif** : +44.0
3. **Peut atteindre +737.1** : L'agent a le potentiel

### **Points Critiques** ‚ùå

1. **Sous-assigne** : 15.3 / 20 (76.5%) vs 17.8 / 20 (89%)

   - **Perte de 2.5 assignments par jour**
   - **Impact business** : -12.5% de chiffre d'affaires

2. **Cancellations massives** : 39.1 / 20

   - **2x plus de cancellations que de bookings !**
   - L'agent annule presque tout

3. **Taux de compl√©tion effondr√©** : 28.3%

   - **Seulement 28% des courses sont compl√©t√©es**
   - vs ~89% baseline

4. **Variance √©norme** : ¬±456.2
   - Agent **tr√®s instable**
   - Performance impr√©visible

---

## üî¨ **DIAGNOSTIC DES CAUSES**

### **1. Reward Function Mal Align√©e** ‚ö†Ô∏è **CAUSE PRINCIPALE**

**Probl√®me** :

```python
# L'agent a appris √† :
# 1. √âviter les late pickups ‚úÖ (5.8 vs 7.3)
# 2. MAIS en ne pas assignant ‚ùå (15.3 vs 17.8)
# 3. ET en cancellant massivement ‚ùå (39.1)
```

**L'agent optimise la reward function, pas le business !**

La reward function actuelle p√©nalise :

- Trop fortement les late pickups
- Pas assez les non-assignments
- Pas assez les cancellations

**R√©sultat** : L'agent pr√©f√®re **ne rien faire** plut√¥t que risquer un late pickup !

### **2. Hyperparam√®tres Non Transf√©rables**

**Optuna a optimis√© pour** :

- 11 drivers, 10 bookings

**Entra√Ænement avec** :

- 3 drivers, 20 bookings

**Impact** :

- Espace d'√©tats et d'actions diff√©rent
- Hyperparam√®tres non adapt√©s
- Performance d√©grad√©e

### **3. Epsilon Decay Trop Rapide**

**Episode 450** :

- Epsilon : 0.0309 (3%)
- Exploration quasi nulle
- Agent fig√© dans strat√©gie sous-optimale

---

## üí° **COMPARAISON AVEC ATTENDU**

| M√©trique        | **Attendu**     | **R√©el**              | **√âcart**       |
| --------------- | --------------- | --------------------- | --------------- |
| Reward moyen    | +700-900        | **-40.6**             | **-740 √† -940** |
| Assignments     | 19.8 / 20 (99%) | **15.3 / 20** (76.5%) | **-22.5%**      |
| Late pickups    | < 2             | 5.8                   | +290%           |
| Taux compl√©tion | 99%             | **28.3%**             | **-71%**        |

**‚Üí Performance 10-20x PIRE que pr√©vu**

---

## üéØ **SOLUTION : R√âOPTIMISATION COMPL√àTE**

### **Plan d'Action Recommand√©** ‚≠ê

#### **√âtape 1 : R√©optimiser Optuna avec Config R√©elle**

```bash
docker exec atmr-api-1 python scripts/rl/tune_hyperparameters.py \
  --trials 50 \
  --episodes 100 \
  --study-name "atmr_3drivers_20bookings"
```

‚ö†Ô∏è **IMPORTANT** : Modifier `hyperparameter_tuner.py` pour forcer :

- `num_drivers = 3`
- `max_bookings = 20`
- `simulation_hours = 8`

**Dur√©e** : 30-45 min  
**B√©n√©fice** : Hyperparam√®tres optimaux pour VOTRE contexte

#### **√âtape 2 : R√©entra√Æner avec Nouveaux Hyperparam√®tres**

```bash
docker exec atmr-api-1 python scripts/rl/train_dqn.py \
  --episodes 1000 \
  --num-drivers 3 \
  --max-bookings 20 \
  --simulation-hours 8 \
  --config data/rl/optimal_config_3drivers.json
```

**Dur√©e** : 30-45 min  
**B√©n√©fice** : Mod√®le production-ready

---

## üîß **MODIFICATIONS N√âCESSAIRES**

### **1. Ajuster Reward Function** (CRITIQUE)

La reward function doit **encourager les assignments** :

```python
# Dans dispatch_env.py

# AUGMENTER bonus pour assignment
if action == "assign":
    reward += 50.0  # Au lieu de 20.0

# R√âDUIRE p√©nalit√© late pickup
if is_late:
    reward -= 10.0  # Au lieu de -30.0

# P√âNALISER fortement les non-assignments
if action == "wait":
    reward -= 20.0  # Nouvelle p√©nalit√©

# P√âNALISER massivement les cancellations
if cancelled:
    reward -= 100.0  # Tr√®s forte p√©nalit√©
```

### **2. Forcer Configuration dans Optuna**

Modifier `hyperparameter_tuner.py` pour ne PAS sugg√©rer `num_drivers` et `max_bookings` :

```python
# Dans hyperparameter_tuner.py, ligne ~60-80
def objective(self, trial: optuna.Trial) -> float:
    # ... autres param√®tres ...

    # FORCER la configuration cible
    num_drivers = 3  # FIXE
    max_bookings = 20  # FIXE
    simulation_hours = 8  # FIXE

    # Ne pas sugg√©rer ces param√®tres
    # num_drivers = trial.suggest_int('num_drivers', 3, 15)  # SUPPRIMER
    # max_bookings = trial.suggest_int('max_bookings', 10, 30)  # SUPPRIMER
```

---

## üìä **COMPARAISON FINALE**

### **Tous les Mod√®les**

| Mod√®le                       | Reward Moyen | Assignments       | Late Pickups | Statut      |
| ---------------------------- | ------------ | ----------------- | ------------ | ----------- |
| **Baseline (100ep, d√©faut)** | -48.9        | 17.8 / 20 (89%)   | 7.3          | R√©f√©rence   |
| **Best (Ep 450, Optuna)**    | **-40.6**    | 15.3 / 20 (76.5%) | **5.8** ‚úÖ   | D√©cevant    |
| **Final (Ep 5000)**          | -1715.5      | 4.3 / 20 (21.5%)  | 1.9          | Catastrophe |

**‚Üí Meilleur mod√®le actuel : Baseline (-48.9) > Best Optuna (-40.6) pour assignments**

---

## üöÄ **RECOMMANDATION URGENTE**

### **Il faut TOUT recommencer avec la bonne approche** :

#### **Phase 1 : Ajuster Reward Function** (20 min)

1. Modifier `backend/services/rl/dispatch_env.py`
2. Augmenter bonus assignments
3. R√©duire p√©nalit√© late pickups
4. P√©naliser fortement non-assignments et cancellations

#### **Phase 2 : Modifier Optuna** (10 min)

1. Modifier `backend/services/rl/hyperparameter_tuner.py`
2. Forcer `num_drivers=3`, `max_bookings=20`, `simulation_hours=8`
3. Ne sugg√©rer que les hyperparam√®tres r√©seau et apprentissage

#### **Phase 3 : R√©optimiser** (30-45 min)

1. Lancer Optuna 50 trials
2. Avec reward function ajust√©e
3. Avec configuration forc√©e

#### **Phase 4 : R√©entra√Æner** (30-45 min)

1. Training 1000 √©pisodes
2. Avec nouveaux hyperparam√®tres
3. Avec early stopping

**Dur√©e totale** : ~2h  
**B√©n√©fice attendu** : Reward +500-700, Assignments 19/20, Late pickups < 3

---

## üéØ **CONCLUSION**

### **Bilan** :

‚ùå **L'entra√Ænement de 5000 √©pisodes a √©chou√©**  
‚ùå **Le meilleur mod√®le n'est pas utilisable en production** (15.3 assignments vs 17.8)  
‚ùå **Les hyperparam√®tres Optuna ne sont pas transf√©rables**

### **Cause racine** :

‚ö†Ô∏è **Reward function non align√©e avec le business**  
‚ö†Ô∏è **Hyperparam√®tres optimis√©s pour mauvaise configuration**

### **Solution** :

1. üîß **Ajuster reward function** (priorit√© : assignments)
2. üéØ **R√©optimiser Optuna** avec 3 drivers fix√©s
3. üöÄ **R√©entra√Æner** avec bonne config
4. ‚úÖ **Early stopping** pour √©viter surentra√Ænement

---

**Voulez-vous que je commence par ajuster la reward function et modifier le code Optuna ?** üîß

---

**G√©n√©r√© le** : 21 octobre 2025, 06:50  
**Mod√®le √©valu√©** : `dqn_best.pth` (Episode 450)  
**Verdict** : ‚ùå Non utilisable en production (assignments trop faibles)  
**Action requise** : Ajuster reward function + R√©optimiser Optuna
