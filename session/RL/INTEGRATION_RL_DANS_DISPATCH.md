# ğŸ”— IntÃ©gration de l'Optimiseur RL dans le Dispatch

**Date** : 21 octobre 2025  
**Statut** : â³ **PRÃŠT** (en attente de la fin de l'entraÃ®nement)

---

## ğŸ“¦ Fichiers CrÃ©Ã©s

âœ… **`backend/services/unified_dispatch/rl_optimizer.py`**  
â†’ Classe `RLDispatchOptimizer` qui amÃ©liore les assignations heuristiques

---

## ğŸ”§ IntÃ©gration dans `engine.py`

### Ã‰tape 1 : Import de l'Optimiseur

Ajouter en haut de `backend/services/unified_dispatch/engine.py` :

```python
from services.unified_dispatch.rl_optimizer import RLDispatchOptimizer
```

### Ã‰tape 2 : Appliquer l'Optimisation

Dans la fonction `run()`, **aprÃ¨s l'heuristique**, ajouter :

```python
# ğŸ§  Optimisation RL (si activÃ©e et modÃ¨le disponible)
if mode == "auto" and len(final_assignments) > 0:
    try:
        logger.info("[Engine] ğŸ§  Tentative d'optimisation RL des assignations...")

        optimizer = RLDispatchOptimizer(
            model_path="data/rl/models/dispatch_optimized_v1.pth",
            max_swaps=10,  # Max 10 rÃ©assignations
            min_improvement=0.5,  # AmÃ©lioration minimale de 0.5 course
        )

        if optimizer.is_available():
            # Convertir assignments en format optimisable
            initial = [
                {
                    "booking_id": a.booking_id,
                    "driver_id": a.driver_id,
                }
                for a in final_assignments
            ]

            # Optimiser
            optimized = optimizer.optimize_assignments(
                initial_assignments=initial,
                bookings=problem["bookings"],
                drivers=regs,
            )

            # Appliquer les changements
            for i, a in enumerate(final_assignments):
                new_driver_id = optimized[i]["driver_id"]
                if a.driver_id != new_driver_id:
                    logger.info(
                        "[Engine] RL swap: Booking %d â†’ Driver %d (was %d)",
                        a.booking_id,
                        new_driver_id,
                        a.driver_id,
                    )
                    a.driver_id = new_driver_id

            logger.info("[Engine] âœ… Optimisation RL terminÃ©e")
        else:
            logger.info("[Engine] â³ Optimiseur RL non disponible (modÃ¨le en cours d'entraÃ®nement)")

    except Exception as e:
        logger.warning("[Engine] âš ï¸ Optimisation RL Ã©chouÃ©e: %s", e)
        # Continuer avec l'heuristique seule
```

### Position d'Insertion

InsÃ©rer ce code **ligne ~490** dans `engine.py`, juste aprÃ¨s :

```python
# ... Heuristique P1 a assignÃ© toutes les courses ...
logger.info("[Engine] Heuristic P1: %d assignÃ©s, %d restants",
            len(h_res.assignments), len(h_res.unassigned_booking_ids))

# ğŸ†• INSÃ‰RER L'OPTIMISATION RL ICI

# âš ï¸ VÃ©rification d'Ã©quitÃ© : TEMPORAIREMENT DÃ‰SACTIVÃ‰E
if False:  # DÃ©sactivÃ© temporairement - voir commentaires ci-dessus
```

---

## ğŸ¯ Comportement de l'Optimiseur

### Mode de Fonctionnement

1. **DÃ©tection Automatique** :

   - VÃ©rifie si le modÃ¨le existe (`data/rl/models/dispatch_optimized_v1.pth`)
   - Si absent â†’ Skip (pas d'erreur, continue avec heuristique)
   - Si prÃ©sent â†’ Active l'optimisation

2. **Optimisation** :

   - Prend les assignations de l'heuristique
   - Calcule l'Ã©cart initial (ex: 5-3-2 â†’ gap=3)
   - SuggÃ¨re jusqu'Ã  10 rÃ©assignations
   - Valide chaque swap (amÃ©lioration â‰¥0.5 ?)
   - Applique uniquement les swaps bÃ©nÃ©fiques

3. **CritÃ¨res de SuccÃ¨s** :
   - **Objectif Principal** : RÃ©duire l'Ã©cart de charge
   - **Contraintes** : Respecter les time windows
   - **ArrÃªt** : Gap â‰¤1 OU 10 swaps atteints

### Logs Produits

```
[Engine] ğŸ§  Tentative d'optimisation RL des assignations...
[RLOptimizer] âœ… ModÃ¨le chargÃ©: data/rl/models/dispatch_optimized_v1.pth
[RLOptimizer] ğŸ§  DÃ©but optimisation: 10 assignments, 3 drivers
[RLOptimizer] Ã‰cart initial: 3 courses
[RLOptimizer] âœ… Swap 1/10 acceptÃ©: Booking 169 â†’ Driver 3 (gap 3 â†’ 2, Î”=1.0)
[RLOptimizer] âœ… Swap 2/10 acceptÃ©: Booking 156 â†’ Driver 4 (gap 2 â†’ 1, Î”=1.0)
[RLOptimizer] ğŸ¯ Optimal atteint (gap=1), arrÃªt
[RLOptimizer] ğŸ‰ Optimisation terminÃ©e: gap 3 â†’ 1 (10 swaps, 2 amÃ©liorations)
[Engine] âœ… Optimisation RL terminÃ©e
```

---

## âš™ï¸ Configuration

### ParamÃ¨tres de l'Optimiseur

| ParamÃ¨tre         | Valeur                                     | Description                                 |
| ----------------- | ------------------------------------------ | ------------------------------------------- |
| `model_path`      | `data/rl/models/dispatch_optimized_v1.pth` | Chemin du modÃ¨le entraÃ®nÃ©                   |
| `max_swaps`       | 10                                         | Nombre max de rÃ©assignations Ã  tenter       |
| `min_improvement` | 0.5                                        | AmÃ©lioration minimale pour accepter un swap |

### Feature Flag (Optionnel)

Pour activer/dÃ©sactiver facilement l'optimiseur RL, ajouter dans `company.autonomous_config` :

```json
{
  "features": {
    "enable_rl_optimization": true
  }
}
```

Puis dans `engine.py` :

```python
if mode == "auto" and getattr(s.features, "enable_rl_optimization", True):
    # ... optimisation RL ...
```

---

## ğŸ“Š RÃ©sultats Attendus

### Avant (Heuristique Seule)

```
Giuseppe : 5 courses  âŒ
Dris     : 3 courses
Yannis   : 2 courses
Ã‰CART    : 3
```

### AprÃ¨s (Heuristique + RL Optimizer)

```
Giuseppe : 4 courses  âœ…
Dris     : 3 courses  âœ…
Yannis   : 3 courses  âœ…
Ã‰CART    : 1
```

**AmÃ©lioration** : **Ã‰cart rÃ©duit de 66%** (3 â†’ 1) ğŸ‰

---

## ğŸ§ª Tests de Validation

### Test 1 : ModÃ¨le Absent

**Setup** : Pas de fichier `.pth`  
**Comportement attendu** :

- Log : "Optimiseur RL non disponible"
- Retour assignations heuristiques intactes
- âœ… Pas d'erreur, dispatch fonctionne normalement

### Test 2 : ModÃ¨le PrÃ©sent, DÃ©jÃ  Optimal

**Setup** : Gap initial = 1  
**Comportement attendu** :

- Log : "DÃ©jÃ  optimal (gap=1), pas d'optimisation"
- Retour assignations inchangÃ©es
- âœ… Ã‰conomie de calcul

### Test 3 : ModÃ¨le PrÃ©sent, Optimisation NÃ©cessaire

**Setup** : Gap initial = 3  
**Comportement attendu** :

- Log : "Optimisation terminÃ©e: gap 3 â†’ 1"
- Assignations modifiÃ©es
- âœ… Ã‰quitÃ© amÃ©liorÃ©e

---

## ğŸš€ Activation en Production

### Ã‰tape 1 : Attendre la Fin de l'EntraÃ®nement

```bash
# VÃ©rifier la progression
docker exec atmr-api-1 python backend/scripts/monitor_rl_training.py

# Attendre "âœ… ENTRAÃNEMENT TERMINÃ‰ !"
```

### Ã‰tape 2 : VÃ©rifier le ModÃ¨le

```bash
# VÃ©rifier que le fichier existe
docker exec atmr-api-1 ls -lh data/rl/models/dispatch_optimized_v1.pth

# Taille attendue : ~1-5 MB
```

### Ã‰tape 3 : IntÃ©grer dans `engine.py`

Ajouter le code d'intÃ©gration (voir ci-dessus)

### Ã‰tape 4 : RedÃ©marrer les Services

```bash
docker restart atmr-api-1
docker restart atmr-celery-worker-1
```

### Ã‰tape 5 : Tester sur un Dispatch

1. Aller dans l'UI : Dispatch Semi-Auto
2. SÃ©lectionner date : 23.10.2025
3. Cliquer "Lancer le Dispatch"
4. VÃ©rifier les logs :
   ```bash
   docker logs atmr-celery-worker-1 --tail 100 | grep "RLOptimizer"
   ```
5. Comparer la rÃ©partition avant/aprÃ¨s

---

## ğŸ“ˆ Monitoring

### MÃ©triques Ã  Suivre

1. **Ã‰cart de Charge** :

   - Avant : Heuristique seule
   - AprÃ¨s : Heuristique + RL
   - Objectif : RÃ©duction â‰¥50%

2. **Temps d'ExÃ©cution** :

   - Heuristique : ~5s
   - RL : +2-3s supplÃ©mentaires
   - Total acceptable : <10s

3. **Taux de SuccÃ¨s** :
   - % de dispatches avec gap â‰¤1
   - Objectif : â‰¥80%

### Logs Ã  Monitorer

```bash
# SuccÃ¨s d'optimisation
docker logs atmr-celery-worker-1 | grep "Optimisation terminÃ©e"

# Swaps effectuÃ©s
docker logs atmr-celery-worker-1 | grep "Swap.*acceptÃ©"

# Erreurs Ã©ventuelles
docker logs atmr-celery-worker-1 | grep "RLOptimizer.*âŒ"
```

---

## ğŸ”„ RÃ©entraÃ®nement

L'optimiseur peut Ãªtre amÃ©liorÃ© continuellement :

1. **Collecter plus de donnÃ©es** :

   - Exporter dispatches de toute la semaine
   - Script : `rl_export_historical_data.py`

2. **RÃ©entraÃ®ner** :

   - Lancer `rl_train_offline.py` avec nouvelles donnÃ©es
   - Le modÃ¨le sera sauvegardÃ© dans le mÃªme fichier

3. **Activer automatiquement** :
   - Pas besoin de modifier le code
   - L'optimiseur rechargera le nouveau modÃ¨le

---

## âš ï¸ DÃ©pannage

### ProblÃ¨me : "ModÃ¨le non trouvÃ©"

**Cause** : Fichier `.pth` absent  
**Solution** : Attendre la fin de l'entraÃ®nement (2-3h)

### ProblÃ¨me : "Optimisation RL Ã©chouÃ©e"

**Cause** : Erreur de chargement du modÃ¨le  
**Solution** :

1. VÃ©rifier les logs dÃ©taillÃ©s
2. VÃ©rifier compatibilitÃ© PyTorch
3. RÃ©entraÃ®ner si nÃ©cessaire

### ProblÃ¨me : "Pas d'amÃ©lioration"

**Cause** : ModÃ¨le sous-entraÃ®nÃ© ou donnÃ©es insuffisantes  
**Solution** :

1. Collecter plus de dispatches historiques
2. RÃ©entraÃ®ner avec 10,000 Ã©pisodes
3. Ajuster `min_improvement` (0.3 au lieu de 0.5)

---

## ğŸ“ Notes Importantes

- âœ… **Pas d'impact si modÃ¨le absent** : Le dispatch fonctionne normalement
- âœ… **Fallback automatique** : En cas d'erreur, retour Ã  l'heuristique
- âœ… **Validation systÃ©matique** : Chaque swap est vÃ©rifiÃ© avant application
- âœ… **Logs dÃ©taillÃ©s** : TraÃ§abilitÃ© complÃ¨te des dÃ©cisions

---

**DerniÃ¨re mise Ã  jour** : 21 octobre 2025, 23:30  
**Statut** : PrÃªt pour intÃ©gration (dÃ¨s que l'entraÃ®nement est terminÃ©)
