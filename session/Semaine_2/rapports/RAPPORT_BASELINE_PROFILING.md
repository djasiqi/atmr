# ğŸ“Š RAPPORT BASELINE - PROFILING BASE DE DONNÃ‰ES

**Date**: 2025-10-20  
**Semaine**: Semaine 2 - Optimisations Base de DonnÃ©es  
**TÃ¢che**: Lundi - Profiling DB (6h)  
**Responsable**: Investigation initiale DB performance

---

## ğŸ¯ Objectif

Ã‰tablir une baseline de performance pour le systÃ¨me de dispatch afin de :
1. Identifier les requÃªtes SQL lentes (>50ms)
2. Mesurer le temps d'exÃ©cution total du dispatch
3. Compter le nombre total de requÃªtes SQL exÃ©cutÃ©es
4. CrÃ©er un point de rÃ©fÃ©rence pour les optimisations futures

---

## ğŸ”§ Outils InstallÃ©s

### 1. **nplusone** (v1.0.0+)
- **Description**: DÃ©tecteur de N+1 queries pour SQLAlchemy
- **Installation**: `pip install nplusone`
- **Usage**: Listener SQLAlchemy pour dÃ©tecter automatiquement les problÃ¨mes de N+1

### 2. **Script de Profiling PersonnalisÃ©**
- **Fichier**: `backend/scripts/profiling/profile_dispatch.py`
- **FonctionnalitÃ©s**:
  - Listeners SQLAlchemy pour mesurer le temps de chaque requÃªte
  - DÃ©tection automatique des requÃªtes >50ms
  - GÃ©nÃ©ration de rapports dÃ©taillÃ©s (console + fichier)
  - Support SQLite et PostgreSQL (configuration dynamique)

---

## ğŸ“ˆ RÃ‰SULTATS BASELINE

### ExÃ©cution du Profiling

**Date d'exÃ©cution**: 2025-10-20  
**Company ID**: 1  
**Environment**: Docker (PostgreSQL)

```
======================================================================
PROFILING DISPATCH - DEMARRAGE
======================================================================
Company ID  : 1
Date        : 2025-10-20
Database    : postgresql+psycopg://atmr:atmr@postgres:5432/atmr
======================================================================

======================================================================
RESULTATS PROFILING
======================================================================

Temps total          : 0.10s
Assignments crees    : 0
Total queries SQL    : 15
Queries lentes (>50ms) : 0
```

### MÃ©triques ClÃ©s

| MÃ©trique | Valeur | Cible |
|----------|--------|-------|
| **Temps total** | 0.10s | < 1.0s âœ… |
| **Nombre de queries** | 15 | < 50 âœ… |
| **Queries lentes** (>50ms) | 0 | 0 âœ… |
| **Assignments crÃ©Ã©s** | 0 | N/A |

---

## ğŸ” OBSERVATIONS

### âœ… Points Positifs

1. **Performance Excellente**: Temps d'exÃ©cution trÃ¨s rapide (100ms)
2. **Aucune Query Lente**: Toutes les requÃªtes < 50ms
3. **Nombre de Queries Raisonnable**: 15 requÃªtes pour un cycle de dispatch

### âš ï¸ Limitations de la Baseline

1. **Pas de Bookings**: Le test a Ã©tÃ© effectuÃ© sans bookings dans la DB
   - Message systÃ¨me : `[Dispatch] No dispatch possible for company 1: no_bookings`
   - Impact : Les requÃªtes les plus lourdes (assignments, optimisations) n'ont pas Ã©tÃ© testÃ©es

2. **DonnÃ©es de Test Manquantes**:
   - Pas de drivers actifs
   - Pas de bookings Ã  assigner
   - Pas de calculs OSRM effectuÃ©s

### ğŸ“Š Profil des RequÃªtes (Estimation)

Les 15 requÃªtes identifiÃ©es sont probablement :
1. Chargement de la configuration Company (1-2 queries)
2. VÃ©rification des drivers disponibles (2-3 queries)
3. Chargement des bookings (1 query, rÃ©sultat vide)
4. VÃ©rification des contraintes (2-3 queries)
5. Queries de mÃ©tadonnÃ©es et configuration (5-7 queries)

---

## ğŸš¨ PROBLÃˆMES IDENTIFIÃ‰S ET RÃ‰SOLUS

### 1. Configuration DB Multi-Environnement âœ…

**ProblÃ¨me Initial**:
```
TypeError: 'client_encoding' is an invalid keyword argument for Connection()
```

**Cause**: 
- `client_encoding` (PostgreSQL) Ã©tait passÃ© Ã  SQLite
- Configuration statique ne dÃ©tectait pas le type de DB

**Solution ImplÃ©mentÃ©e**:
```python
# backend/config.py
class DevelopmentConfig(Config):
    @staticmethod
    def init_app(app):
        db_uri = app.config.get('SQLALCHEMY_DATABASE_URI', '')
        engine_options = dict(Config.SQLALCHEMY_ENGINE_OPTIONS)
        
        if db_uri.startswith('sqlite'):
            engine_options['connect_args'] = {"check_same_thread": False}
        elif db_uri.startswith('postgresql'):
            engine_options['connect_args'] = {"client_encoding": "utf8"}
        
        app.config['SQLALCHEMY_ENGINE_OPTIONS'] = engine_options
```

**RÃ©sultat**: âœ… Compatible SQLite (local) et PostgreSQL (Docker)

### 2. Bug Script Profiling âœ…

**ProblÃ¨me**: `UnboundLocalError: sorted_queries`

**Solution**: DÃ©claration de la variable avant utilisation conditionnelle
```python
sorted_queries = sorted(queries_log, key=lambda x: x['time'], reverse=True) if queries_log else []
```

---

## ğŸ¯ PROCHAINES Ã‰TAPES

### Phase 1: Profiling avec DonnÃ©es RÃ©elles
1. **CrÃ©er des donnÃ©es de test rÃ©alistes**:
   - 50-100 bookings
   - 10-20 drivers actifs
   - Distribution gÃ©ographique variÃ©e

2. **RÃ©-exÃ©cuter le profiling**:
   ```bash
   docker exec atmr-api-1 python scripts/profiling/profile_dispatch.py
   ```

3. **Analyser les rÃ©sultats**:
   - Identifier les requÃªtes N+1
   - Mesurer l'impact des calculs OSRM
   - Ã‰valuer les temps de rÃ©ponse sous charge

### Phase 2: Optimisations CiblÃ©es (Mardi-Mercredi)
1. **Indexation DB**: CrÃ©er index sur colonnes frÃ©quemment utilisÃ©es
2. **Eager Loading**: Remplacer lazy loading par `joinedload`/`selectinload`
3. **Query Optimization**: RÃ©duire le nombre de queries via JOIN

### Phase 3: Validation (Jeudi-Vendredi)
1. **Benchmarking**: Comparer avant/aprÃ¨s optimisations
2. **Documentation**: Mettre Ã  jour le guide d'optimisation
3. **Tests de RÃ©gression**: Garantir aucune rÃ©gression fonctionnelle

---

## ğŸ“ COMMANDES UTILES

### ExÃ©cuter le Profiling

**Dans Docker**:
```bash
docker exec atmr-api-1 python scripts/profiling/profile_dispatch.py
```

**Local (SQLite)**:
```bash
cd backend
python scripts/profiling/profile_dispatch.py
```

### Consulter les RÃ©sultats

```bash
docker exec atmr-api-1 cat scripts/profiling/profiling_results.txt
```

### Activer DÃ©tection N+1 (optionnel)

Modifier `backend/app.py` pour activer `nplusone`:
```python
from nplusone.ext.flask_sqlalchemy import NPlusOne
nplusone = NPlusOne(app)
```

---

## ğŸ“š RÃ‰FÃ‰RENCES

1. **SQLAlchemy Performance**: https://docs.sqlalchemy.org/en/20/orm/queryguide/performance.html
2. **nplusone Documentation**: https://github.com/jmcarp/nplusone
3. **PostgreSQL Indexing**: https://www.postgresql.org/docs/current/indexes.html
4. **Semaine 2 Guide**: `session/Semaine_2/GUIDE_DETAILLE.md`

---

## âœ… VALIDATION

- [x] Outils de profiling installÃ©s
- [x] Script de profiling crÃ©Ã© et testÃ©
- [x] Configuration DB multi-environnement corrigÃ©e
- [x] Rapport baseline gÃ©nÃ©rÃ©
- [ ] DonnÃ©es de test crÃ©Ã©es (Ã€ faire: Phase 1)
- [ ] Profiling avec charge rÃ©elle (Ã€ faire: Phase 1)

---

**Conclusion**: Le systÃ¨me de profiling est opÃ©rationnel et prÃªt pour les tests avec donnÃ©es rÃ©elles. La baseline actuelle montre des performances excellentes, mais ne reflÃ¨te pas encore la charge rÃ©elle du systÃ¨me. Les prochaines Ã©tapes consistent Ã  crÃ©er des donnÃ©es de test reprÃ©sentatives pour identifier les vÃ©ritables goulots d'Ã©tranglement.

**Statut**: âœ… **BASELINE Ã‰TABLIE** - PrÃªt pour phase d'optimisation

