#!/usr/bin/env python3
"""Script de validation pour l'√âtape 4 - Alertes Proactives + Explicabilit√©.

Ce script teste:
- Service d'alertes proactives
- Routes REST
- Socket.IO handlers
- Syst√®me de debounce
- Int√©gration avec delay_predictor.pkl

Auteur: ATMR Project - RL Team
Date: 21 octobre 2025
"""

import json
import logging
import sys
from datetime import UTC, datetime, timedelta
from pathlib import Path

# Configuration du logging
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)


def test_proactive_alerts_service():
    """Test du service d'alertes proactives."""
    logger.info("üß™ Test du service d'alertes proactives...")

    try:
        from services.proactive_alerts import ProactiveAlertsService

        # Initialiser le service
        service = ProactiveAlertsService()

        # Donn√©es de test
        test_booking = {
            "id": "test_123",
            "pickup_lat": 46.2044,
            "pickup_lon": 6.1432,
            "pickup_time": (datetime.now(UTC) + timedelta(minutes=20)).isoformat(),
            "priority": 3,
            "is_outbound": True,
            "estimated_duration": 30
        }

        test_driver = {
            "id": "driver_456",
            "lat": 46.2100,
            "lon": 6.1400,
            "current_bookings": 2,
            "load": 0,
            "type": "REGULAR",
            "available": True
        }

        # Test analyse de risque
        result = service.check_delay_risk(test_booking, test_driver)

        assert "delay_probability" in result
        assert "risk_level" in result
        assert "explanation" in result
        assert "should_alert" in result

        logger.info("‚úÖ Analyse de risque: %s (%.1f%%)", result["risk_level"], result["delay_probability"]*100)

        # Test explicabilit√© RL
        rl_decision = {
            "q_values": {"action_1": 0.8, "action_2": 0.6},
            "confidence": 0.85,
            "reward_components": {"punctuality": 0.7, "distance": 0.3}
        }

        explanation = service.get_explanation_for_decision(
            booking_id="test_123",
            driver_id="driver_456",
            rl_decision=rl_decision
        )

        assert "decision_factors" in explanation
        assert "alternative_options" in explanation

        logger.info("‚úÖ Explicabilit√© RL fonctionnelle")

        # Test syst√®me de debounce
        analysis_result = {
            "booking_id": "test_booking",
            "driver_id": "driver_456",
            "delay_probability": 0.8,
            "risk_level": "high",
            "should_alert": True,
            "explanation": {"test": "explanation"},
            "timestamp": datetime.now(UTC).isoformat()
        }

        # Premier envoi
        success1 = service.send_proactive_alert(analysis_result, "test_company")
        logger.info("‚úÖ Premier envoi d'alerte: %s", "Succ√®s" if success1 else "√âchec")

        # Deuxi√®me envoi (doit √™tre debounced)
        success2 = service.send_proactive_alert(analysis_result, "test_company")
        logger.info("‚úÖ Deuxi√®me envoi (debounced): %s", "Succ√®s" if success2 else "√âchec")

        # Test statistiques
        stats = service.get_alert_statistics()
        assert "total_alerts_sent" in stats
        logger.info("‚úÖ Statistiques: %s alertes", stats["total_alerts_sent"])

        logger.info("üéâ Service d'alertes proactives valid√© avec succ√®s!")
        return True

    except Exception as e:
        logger.error("‚ùå Erreur test service: %s", e)
        return False


def test_routes():
    """Test des routes REST."""
    logger.info("üß™ Test des routes REST...")

    try:
        from routes.proactive_alerts import _get_mock_booking_data, _get_mock_driver_data, proactive_alerts_bp

        # Test donn√©es mock
        booking_data = _get_mock_booking_data("123")
        driver_data = _get_mock_driver_data("456")

        assert booking_data is not None
        assert driver_data is not None
        assert booking_data["id"] == "123"
        assert driver_data["id"] == "456"

        logger.info("‚úÖ Donn√©es mock fonctionnelles")

        # Test blueprint
        assert proactive_alerts_bp.name == "proactive_alerts"
        assert proactive_alerts_bp.url_prefix == "/api/alerts"

        logger.info("‚úÖ Blueprint configur√© correctement")

        logger.info("üéâ Routes REST valid√©es avec succ√®s!")
        return True

    except Exception as e:
        logger.error("‚ùå Erreur test routes: %s", e)
        return False


def test_socketio_handlers():
    """Test des handlers Socket.IO."""
    logger.info("üß™ Test des handlers Socket.IO...")

    try:
        from sockets.proactive_alerts import (
            broadcast_delay_alert,
            broadcast_rl_explanation,
            get_active_connections_stats,
        )

        # Test fonctions de diffusion
        analysis_result = {
            "booking_id": "test_123",
            "driver_id": "driver_456",
            "delay_probability": 0.8,
            "risk_level": "high",
            "explanation": {"test": "explanation"}
        }

        # Mock SocketIO avec type Any pour √©viter les erreurs de type
        mock_socketio = type("MockSocketIO", (), {
            "emit": lambda self, event, data, room=None: True
        })()

        success = broadcast_delay_alert("test_company", analysis_result, mock_socketio)  # type: ignore
        assert success is True

        explanation = {
            "booking_id": "test_123",
            "driver_id": "driver_456",
            "decision_factors": [],
            "alternative_options": []
        }

        success = broadcast_rl_explanation("test_company", explanation, mock_socketio)  # type: ignore
        assert success is True

        # Test statistiques connexions
        stats = get_active_connections_stats()
        assert "total_companies" in stats
        assert "total_connections" in stats

        logger.info("‚úÖ Handlers Socket.IO fonctionnels")

        logger.info("üéâ Handlers Socket.IO valid√©s avec succ√®s!")
        return True

    except Exception as e:
        logger.error("‚ùå Erreur test Socket.IO: %s", e)
        return False


def test_integration():
    """Test d'int√©gration compl√®te."""
    logger.info("üß™ Test d'int√©gration compl√®te...")

    try:
        # Test int√©gration avec delay_predictor

        service = ProactiveAlertsService()

        # V√©rifier que le service peut charger le delay_predictor
        if service.delay_predictor is not None:
            logger.info("‚úÖ DelayMLPredictor charg√© avec succ√®s")
        else:
            logger.warning("‚ö†Ô∏è DelayMLPredictor non disponible (fallback heuristique)")

        # Test avec donn√©es r√©alistes
        realistic_booking = {
            "id": "realistic_123",
            "pickup_lat": 46.2044,
            "pickup_lon": 6.1432,
            "pickup_time": (datetime.now(UTC) + timedelta(minutes=5)).isoformat(),  # Risque √©lev√©
            "priority": 4,
            "is_outbound": True,
            "estimated_duration": 30
        }

        realistic_driver = {
            "id": "driver_realistic",
            "lat": 46.3000,  # Loin
            "lon": 6.2000,
            "current_bookings": 4,  # Charge √©lev√©e
            "load": 0,
            "type": "REGULAR",
            "available": True
        }

        result = service.check_delay_risk(realistic_booking, realistic_driver)

        logger.info("‚úÖ Analyse r√©aliste: %s (%.1f%%)", result["risk_level"], result["delay_probability"]*100)

        # V√©rifier que le syst√®me d√©tecte bien le risque √©lev√©
        if result["risk_level"] in ["medium", "high"]:
            logger.info("‚úÖ D√©tection de risque √©lev√© fonctionnelle")
        else:
            logger.warning("‚ö†Ô∏è Risque √©lev√© non d√©tect√©")

        logger.info("üéâ Int√©gration compl√®te valid√©e avec succ√®s!")
        return True

    except Exception as e:
        logger.error("‚ùå Erreur test int√©gration: %s", e)
        return False


def generate_validation_report():
    """G√©n√®re un rapport de validation."""
    logger.info("üìä G√©n√©ration du rapport de validation...")

    report = {
        "timestamp": datetime.now(UTC).isoformat(),
        "step": "√âtape 4 - Alertes Proactives + Explicabilit√©",
        "tests": {
            "proactive_alerts_service": False,
            "routes": False,
            "socketio_handlers": False,
            "integration": False
        },
        "summary": {
            "total_tests": 4,
            "passed": 0,
            "failed": 0
        }
    }

    # Ex√©cuter les tests
    tests = [
        ("proactive_alerts_service", test_proactive_alerts_service),
        ("routes", test_routes),
        ("socketio_handlers", test_socketio_handlers),
        ("integration", test_integration)
    ]

    for test_name, test_func in tests:
        try:
            result = test_func()
            report["tests"][test_name] = result
            if result:
                report["summary"]["passed"] += 1
            else:
                report["summary"]["failed"] += 1
        except Exception as e:
            logger.error("‚ùå Test %s √©chou√©: %s", test_name, e)
            report["summary"]["failed"] += 1

    # Sauvegarder le rapport
    report_path = Path("backend/data/rl/validation_reports")
    report_path.mkdir(parents=True, exist_ok=True)

    report_file = report_path / "step4validation_report.json"
    with Path(report_file, "w", encoding="utf-8").open() as f:
        json.dump(report, f, indent=2, ensure_ascii=False)

    logger.info("üìÑ Rapport sauvegard√©: %s", report_file)

    # Afficher le r√©sum√©
    logger.info("=" * 60)
    logger.info("üìä RAPPORT DE VALIDATION - √âTAPE 4")
    logger.info("=" * 60)
    logger.info("Tests ex√©cut√©s: %s", report["summary"]["total_tests"])
    logger.info("Tests r√©ussis: %s", report["summary"]["passed"])
    logger.info("Tests √©chou√©s: %s", report["summary"]["failed"])
    logger.info("")

    for test_name, result in report["tests"].items():
        status = "‚úÖ R√âUSSI" if result else "‚ùå √âCHOU√â"
        logger.info("%s: %s", test_name, status)

    logger.info("=" * 60)

    if report["summary"]["failed"] == 0:
        logger.info("üéâ TOUS LES TESTS SONT R√âUSSIS!")
        logger.info("‚úÖ L'√âtape 4 - Alertes Proactives + Explicabilit√© est valid√©e!")
    else:
        logger.warning("‚ö†Ô∏è %s test(s) ont √©chou√©", report["summary"]["failed"])
        logger.warning("‚ùå L'√âtape 4 n√©cessite des corrections")

    return report


def main():
    """Fonction principale."""
    logger.info("üöÄ D√©but de la validation de l'√âtape 4")
    logger.info("=" * 60)

    try:
        report = generate_validation_report()

        if report["summary"]["failed"] == 0:
            logger.info("üéâ VALIDATION R√âUSSIE!")
            sys.exit(0)
        else:
            logger.error("‚ùå VALIDATION √âCHOU√âE!")
            sys.exit(1)

    except Exception as e:
        logger.error("‚ùå Erreur critique: %s", e)
        sys.exit(1)


if __name__ == "__main__":
    main()
