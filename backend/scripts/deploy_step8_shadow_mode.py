#!/usr/bin/env python3
# ruff: noqa: E402
"""Script de d√©ploiement pour l'√âtape 8 - Shadow Mode Enrichi & KPIs.

Orchestre le d√©ploiement complet du syst√®me de comparaison
humain vs RL avec g√©n√©ration de rapports quotidiens.
"""

import json
import logging
import sys
from datetime import UTC, datetime
from pathlib import Path

# Ajouter le r√©pertoire backend au path
backend_path = Path(__file__).parent
sys.path.insert(0, str(backend_path))

from services.rl.shadow_mode_manager import ShadowModeManager


def setup_logging():
    """Configure le logging."""
    timestamp = datetime.now(UTC).strftime("%Y%m%d_%H%M%S")
    logging.basicConfig(
        level=logging.INFO,
        format="%(asctime)s - %(levelname)s - %(message)s",
        handlers=[
            logging.FileHandler(f"logs/deploy_step8_{timestamp}.log"),
            logging.StreamHandler()
        ]
    )
    return logging.getLogger(__name__)


def run_tests():
    """Ex√©cute les tests du shadow mode."""
    logger = logging.getLogger(__name__)
    logger.info("üß™ Ex√©cution des tests Shadow Mode...")
    
    try:
        # Importer et ex√©cuter les tests
        from tests.test_shadow_mode import run_shadow_mode_tests
        run_shadow_mode_tests()
        
        logger.info("‚úÖ Tests Shadow Mode r√©ussis")
        return True
        
    except Exception as e:
        logger.error("‚ùå Erreur lors des tests: %s", e)
        return False


def validate_implementation():
    """Valide l'impl√©mentation compl√®te."""
    logger = logging.getLogger(__name__)
    logger.info("üîç Validation de l'impl√©mentation...")
    
    try:
        # Importer et ex√©cuter la validation
        from scripts.validate_step8_shadow_mode import Step8ValidationSuite
        
        validator = Step8ValidationSuite()
        validator.run_all_validations()
        success = validator.generate_report()
        
        if success:
            logger.info("‚úÖ Validation compl√®te r√©ussie")
        else:
            logger.error("‚ùå Validation √©chou√©e")
        
        return success
        
    except Exception as e:
        logger.error("‚ùå Erreur lors de la validation: %s", e)
        return False


def create_sample_data():
    """Cr√©e des donn√©es d'exemple pour d√©monstration."""
    logger = logging.getLogger(__name__)
    logger.info("üìä Cr√©ation de donn√©es d'exemple...")
    
    try:
        # Cr√©er le gestionnaire
        manager = ShadowModeManager(data_dir="data/rl/shadow_mode")
        
        # Donn√©es d'exemple pour plusieurs entreprises
        companies_data = [
            {
                "company_id": "company_alpha",
                "decisions": [
                    {
                        "booking_id": "booking_alpha_1",
                        "human_decision": {
                            "driver_id": "driver_h1",
                            "eta_minutes": 30,
                            "delay_minutes": 10,
                            "distance_km": 15.0,
                            "driver_load": 0.8,
                            "confidence": 0.7
                        },
                        "rl_decision": {
                            "driver_id": "driver_r1",
                            "eta_minutes": 25,
                            "delay_minutes": 5,
                            "distance_km": 12.5,
                            "driver_load": 0.6,
                            "confidence": 0.9,
                            "alternative_drivers": ["driver_r1", "driver_alt1", "driver_alt2"],
                            "respects_time_window": True,
                            "driver_available": True,
                            "passenger_count": 2,
                            "in_service_area": True
                        },
                        "context": {
                            "avg_eta": 28,
                            "avg_distance": 14.0,
                            "avg_load": 0.7,
                            "vehicle_capacity": 4,
                            "driver_performance": {
                                "driver_r1": {"rating": 4.5},
                                "driver_h1": {"rating": 4.2}
                            }
                        }
                    },
                    {
                        "booking_id": "booking_alpha_2",
                        "human_decision": {
                            "driver_id": "driver_h2",
                            "eta_minutes": 20,
                            "delay_minutes": 0,
                            "distance_km": 10.0,
                            "driver_load": 0.5,
                            "confidence": 0.9
                        },
                        "rl_decision": {
                            "driver_id": "driver_h2",  # Accord avec l'humain
                            "eta_minutes": 20,
                            "delay_minutes": 0,
                            "distance_km": 10.0,
                            "driver_load": 0.5,
                            "confidence": 0.95,
                            "alternative_drivers": ["driver_h2", "driver_alt3"],
                            "respects_time_window": True,
                            "driver_available": True,
                            "passenger_count": 1,
                            "in_service_area": True
                        },
                        "context": {
                            "avg_eta": 28,
                            "avg_distance": 14.0,
                            "avg_load": 0.7,
                            "vehicle_capacity": 4,
                            "driver_performance": {
                                "driver_h2": {"rating": 4.8}
                            }
                        }
                    }
                ]
            },
            {
                "company_id": "company_beta",
                "decisions": [
                    {
                        "booking_id": "booking_beta_1",
                        "human_decision": {
                            "driver_id": "driver_h3",
                            "eta_minutes": 35,
                            "delay_minutes": 15,
                            "distance_km": 18.0,
                            "driver_load": 0.9,
                            "confidence": 0.6
                        },
                        "rl_decision": {
                            "driver_id": "driver_r2",
                            "eta_minutes": 28,
                            "delay_minutes": 8,
                            "distance_km": 15.0,
                            "driver_load": 0.7,
                            "confidence": 0.85,
                            "alternative_drivers": ["driver_r2", "driver_alt4"],
                            "respects_time_window": True,
                            "driver_available": True,
                            "passenger_count": 3,
                            "in_service_area": True
                        },
                        "context": {
                            "avg_eta": 32,
                            "avg_distance": 16.0,
                            "avg_load": 0.8,
                            "vehicle_capacity": 4,
                            "driver_performance": {
                                "driver_r2": {"rating": 4.3},
                                "driver_h3": {"rating": 3.9}
                            }
                        }
                    }
                ]
            }
        ]
        
        # Enregistrer toutes les d√©cisions
        for company_data in companies_data:
            company_id = company_data["company_id"]
            
            for decision_data in company_data["decisions"]:
                manager.log_decision_comparison(
                    company_id=company_id,
                    booking_id=decision_data["booking_id"],
                    human_decision=decision_data["human_decision"],
                    rl_decision=decision_data["rl_decision"],
                    context=decision_data["context"]
                )
        
        # G√©n√©rer les rapports quotidiens
        for company_data in companies_data:
            company_id = company_data["company_id"]
            report = manager.generate_daily_report(company_id)
            
            logger.info("üìä Rapport g√©n√©r√© pour %s: %s d√©cisions", company_id, report["total_decisions"])
        
        # G√©n√©rer les r√©sum√©s d'entreprise
        for company_data in companies_data:
            company_id = company_data["company_id"]
            summary = manager.get_company_summary(company_id, 7)
            
            logger.info("üìà R√©sum√© g√©n√©r√© pour %s: %s d√©cisions sur 7 jours", company_id, summary["total_decisions"])
        
        logger.info("‚úÖ Donn√©es d'exemple cr√©√©es avec succ√®s")
        return True
        
    except Exception as e:
        logger.error("‚ùå Erreur lors de la cr√©ation des donn√©es: %s", e)
        return False


def update_app_integration():
    """Met √† jour l'int√©gration avec l'application Flask."""
    logger = logging.getLogger(__name__)
    logger.info("üîó Mise √† jour de l'int√©gration Flask...")
    
    try:
        # V√©rifier que les routes existent
        routes_file = Path("routes/shadow_mode_routes.py")
        if not routes_file.exists():
            logger.error("‚ùå Fichier routes/shadow_mode_routes.py non trouv√©")
            return False
        
        # V√©rifier que le gestionnaire existe
        manager_file = Path("services/rl/shadow_mode_manager.py")
        if not manager_file.exists():
            logger.error("‚ùå Fichier services/rl/shadow_mode_manager.py non trouv√©")
            return False
        
        # V√©rifier que les tests existent
        tests_file = Path("tests/test_shadow_mode.py")
        if not tests_file.exists():
            logger.error("‚ùå Fichier tests/test_shadow_mode.py non trouv√©")
            return False
        
        logger.info("‚úÖ Int√©gration Flask valid√©e")
        return True
        
    except Exception as e:
        logger.error("‚ùå Erreur lors de la mise √† jour de l'int√©gration: %s", e)
        return False


def generate_deployment_summary():
    """G√©n√®re un r√©sum√© du d√©ploiement."""
    logger = logging.getLogger(__name__)
    logger.info("üìã G√©n√©ration du r√©sum√© de d√©ploiement...")
    
    try:
        summary = {
            "deployment_date": datetime.now(UTC).isoformat(),
            "step": "√âtape 8 - Shadow Mode Enrichi & KPIs",
            "components": {
                "shadow_mode_manager": {
                    "file": "services/rl/shadow_mode_manager.py",
                    "description": "Gestionnaire principal du shadow mode avec KPIs",
                    "features": [
                        "Comparaison humain vs RL",
                        "Calcul des KPIs d√©taill√©s",
                        "G√©n√©ration de rapports quotidiens",
                        "Export CSV/JSON automatis√©"
                    ]
                },
                "shadow_mode_routes": {
                    "file": "routes/shadow_mode_routes.py",
                    "description": "Routes API pour le shadow mode",
                    "endpoints": [
                        "/api/shadow-mode/reports/daily/<company_id>",
                        "/api/shadow-mode/reports/summary/<company_id>",
                        "/api/shadow-mode/kpis/metrics/<company_id>",
                        "/api/shadow-mode/kpis/export/<company_id>",
                        "/api/shadow-mode/health",
                        "/api/shadow-mode/companies"
                    ]
                },
                "shadow_mode_tests": {
                    "file": "tests/test_shadow_mode.py",
                    "description": "Tests complets du shadow mode",
                    "test_categories": [
                        "Tests unitaires ShadowModeManager",
                        "Tests de calcul des KPIs",
                        "Tests d'enregistrement des d√©cisions",
                        "Tests de g√©n√©ration de rapports",
                        "Tests d'export de fichiers",
                        "Tests d'int√©gration"
                    ]
                }
            },
            "kpis_implemented": [
                "eta_delta - Diff√©rence ETA humain vs RL",
                "delay_delta - Diff√©rence retard humain vs RL",
                "second_best_driver - Second meilleur driver sugg√©r√©",
                "rl_confidence - Confiance RL dans la d√©cision",
                "human_confidence - Confiance humaine (si disponible)",
                "decision_reasons - Raisons de la d√©cision RL",
                "constraint_violations - Violations de contraintes",
                "performance_impact - Impact sur performance globale"
            ],
            "daily_reports_features": [
                "Statistiques quotidiennes d√©taill√©es",
                "R√©sum√© des KPIs avec insights",
                "Recommandations bas√©es sur les donn√©es",
                "Export automatique en JSON et CSV",
                "Analyse des tendances multi-jours"
            ],
            "api_endpoints": {
                "reports": {
                    "daily": "GET /api/shadow-mode/reports/daily/<company_id>",
                    "summary": "GET /api/shadow-mode/reports/summary/<company_id>",
                    "log_decision": "POST /api/shadow-mode/reports/daily/<company_id>"
                },
                "kpis": {
                    "metrics": "GET /api/shadow-mode/kpis/metrics/<company_id>",
                    "export": "GET /api/shadow-mode/kpis/export/<company_id>"
                },
                "utility": {
                    "health": "GET /api/shadow-mode/health",
                    "companies": "GET /api/shadow-mode/companies"
                }
            },
            "data_structure": {
                "storage": "data/rl/shadow_mode/<company_id>/",
                "files": [
                    "report_YYYY-MM-DD.json - Rapport quotidien JSON",
                    "data_YYYY-MM-DD.csv - Donn√©es tabulaires CSV"
                ],
                "retention": "30 jours par d√©faut (configurable)"
            }
        }
        
        # Sauvegarder le r√©sum√©
        summary_file = Path("data/rl/shadow_mode/deployment_summary.json")
        summary_file.parent.mkdir(parents=True, exist_ok=True)
        
        with Path(summary_file, "w", encoding="utf-8").open() as f:
            json.dump(summary, f, indent=2, ensure_ascii=False)
        
        logger.info("üìã R√©sum√© sauvegard√©: %s", summary_file)
        
        # Afficher le r√©sum√©
        print("\n" + "=" * 70)
        print("üìä R√âSUM√â DU D√âPLOIEMENT √âTAPE 8 - SHADOW MODE ENRICHI & KPIs")
        print("=" * 70)
        
        print("Date de d√©ploiement: {summary['deployment_date']}")
        print("√âtape: {summary['step']}")
        
        print("\nüîß COMPOSANTS D√âPLOY√âS:")
        for _component, _details in summary["components"].items():
            print("  ‚Ä¢ {component}: {details['file']}")
            print("    {details['description']}")
        
        print("\nüìä KPIs IMPL√âMENT√âS:")
        for _kpi in summary["kpis_implemented"]:
            print("  ‚Ä¢ {kpi}")
        
        print("\nüìà FONCTIONNALIT√âS DES RAPPORTS QUOTIDIENS:")
        for _feature in summary["daily_reports_features"]:
            print("  ‚Ä¢ {feature}")
        
        print("\nüåê ENDPOINTS API:")
        for _category, endpoints in summary["api_endpoints"].items():
            print("  {category.upper()}:")
            for _name, _endpoint in endpoints.items():
                print("    ‚Ä¢ {name}: {endpoint}")
        
        print("\nüíæ STRUCTURE DES DONN√âES:")
        print("  Stockage: {summary['data_structure']['storage']}")
        for _file_type in summary["data_structure"]["files"]:
            print("  ‚Ä¢ {file_type}")
        print("  R√©tention: {summary['data_structure']['retention']}")
        
        print("\n‚úÖ D√âPLOIEMENT √âTAPE 8 TERMIN√â AVEC SUCC√àS!")
        
        return True
        
    except Exception as e:
        logger.error("‚ùå Erreur lors de la g√©n√©ration du r√©sum√©: %s", e)
        return False


def main():
    """Fonction principale de d√©ploiement."""
    logger = setup_logging()
    
    logger.info("üöÄ D√©marrage du d√©ploiement √âtape 8 - Shadow Mode Enrichi & KPIs")
    logger.info("=" * 70)
    
    # √âtapes de d√©ploiement
    steps = [
        ("Tests", run_tests),
        ("Validation", validate_implementation),
        ("Donn√©es d'exemple", create_sample_data),
        ("Int√©gration Flask", update_app_integration),
        ("R√©sum√© de d√©ploiement", generate_deployment_summary)
    ]
    
    success_count = 0
    total_steps = len(steps)
    
    for step_name, step_func in steps:
        logger.info("\nüìã √âtape: %s", step_name)
        try:
            if step_func():
                logger.info("‚úÖ %s r√©ussi", step_name)
                success_count += 1
            else:
                logger.error("‚ùå %s √©chou√©", step_name)
        except Exception as e:
            logger.error("‚ùå Erreur dans %s: %s", step_name, e)
    
    # R√©sultat final
    logger.info("\n" + "=" * 70)
    logger.info("üìä R√âSULTAT DU D√âPLOIEMENT: %s/%s √©tapes r√©ussies", success_count, total_steps)
    
    if success_count == total_steps:
        logger.info("üéâ D√âPLOIEMENT √âTAPE 8 R√âUSSI!")
        logger.info("‚úÖ Shadow Mode Enrichi & KPIs d√©ploy√© avec succ√®s")
        logger.info("‚úÖ KPIs d√©taill√©s op√©rationnels")
        logger.info("‚úÖ Rapports quotidiens fonctionnels")
        logger.info("‚úÖ Export CSV/JSON automatis√©")
        logger.info("‚úÖ Routes API int√©gr√©es")
        logger.info("‚úÖ Tests complets valid√©s")
        return True
    logger.error("‚ö†Ô∏è  D√âPLOIEMENT PARTIEL: %s √©tapes √©chou√©es", total_steps - success_count)
    logger.error("‚ùå Corriger les erreurs avant la mise en production")
    return False


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
