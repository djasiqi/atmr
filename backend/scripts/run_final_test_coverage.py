#!/usr/bin/env python3
# pyright: reportMissingImports=false
"""Script final pour ex√©cuter tous les tests et g√©n√©rer un rapport de couverture.

Ce script orchestre l'ex√©cution de tous les tests cr√©√©s pour l'√âtape 10
et g√©n√®re un rapport complet de la couverture de tests.
"""

import json
import sys
from datetime import UTC, datetime
from pathlib import Path

# Ajouter le r√©pertoire backend au path Python
backend_dir = Path(__file__).parent.parent
sys.path.insert(0, str(backend_dir))

def execute_all_tests():
    """Ex√©cute tous les tests cr√©√©s."""
    print("üöÄ Ex√©cution de tous les tests cr√©√©s pour l'√âtape 10")
    print("üìÖ {datetime.now(UTC).strftime('%Y-%m-%d %H:%M:%S')} UTC")
    
    # Liste des modules de test √† ex√©cuter
    test_modules = [
        "tests.rl.test_per_comprehensive",
        "tests.rl.test_action_masking_comprehensive",
        "tests.rl.test_reward_shaping_comprehensive",
        "tests.rl.test_integration_comprehensive",
        "tests.test_alerts_comprehensive",
        "tests.test_shadow_mode_comprehensive",
        "tests.test_docker_production_comprehensive"
    ]
    
    results = []
    total_tests = 0
    total_passed = 0
    
    for module in test_modules:
        print("\nüß™ Ex√©cution de {module}")
        
        try:
            # Importer le module
            spec = __import__(module, fromlist=[""])
            
            # Ex√©cuter les tests
            if hasattr(spec, "run_tests"):
                passed, total = spec.run_tests()
            elif hasattr(spec, "run_per_tests"):
                passed, total = spec.run_per_tests()
            elif hasattr(spec, "run_masking_tests"):
                passed, total = spec.run_masking_tests()
            elif hasattr(spec, "run_reward_tests"):
                passed, total = spec.run_reward_tests()
            elif hasattr(spec, "run_integration_tests"):
                passed, total = spec.run_integration_tests()
            elif hasattr(spec, "run_alerts_tests"):
                passed, total = spec.run_alerts_tests()
            elif hasattr(spec, "run_shadow_mode_tests"):
                passed, total = spec.run_shadow_mode_tests()
            elif hasattr(spec, "run_docker_production_tests"):
                passed, total = spec.run_docker_production_tests()
            else:
                # Essayer d'ex√©cuter toutes les m√©thodes de test
                passed, total = 0, 0
                for attr_name in dir(spec):
                    if attr_name.startswith("run_") and attr_name.endswith("_tests"):
                        method = getattr(spec, attr_name)
                        try:
                            p, t = method()
                            passed += p
                            total += t
                        except Exception as e:
                            print("  ‚ùå Erreur dans {attr_name}: {e}")
            
            success_rate = (passed / total * 100) if total > 0 else 0
            status = "success" if passed == total else "partial" if passed > 0 else "failed"
            
            results.append({
                "module": module,
                "passed": passed,
                "total": total,
                "success_rate": success_rate,
                "status": status
            })
            
            total_tests += total
            total_passed += passed
            
            print("  üìä R√©sultats: {passed}/{total} ({success_rate")
            
        except Exception as e:
            print("  ‚ùå Erreur lors de l'ex√©cution: {e}")
            results.append({
                "module": module,
                "passed": 0,
                "total": 0,
                "success_rate": 0,
                "status": "error",
                "error": str(e)
            })
    
    return results, total_tests, total_passed

def generate_coverage_report(results, total_tests, total_passed):
    """G√©n√®re un rapport de couverture complet."""
    print("\nüìä G√©n√©ration du rapport de couverture")
    
    # Calculer les m√©triques globales
    global_success_rate = (total_passed / total_tests * 100) if total_tests > 0 else 0
    
    # Analyser les modules RL
    rl_modules = [r for r in results if "rl" in r["module"]]
    rl_tests = sum(r["total"] for r in rl_modules)
    rl_passed = sum(r["passed"] for r in rl_modules)
    rl_success_rate = (rl_passed / rl_tests * 100) if rl_tests > 0 else 0
    
    # Analyser les modules d'alertes
    alerts_modules = [r for r in results if "alerts" in r["module"]]
    alerts_tests = sum(r["total"] for r in alerts_modules)
    alerts_passed = sum(r["passed"] for r in alerts_modules)
    alerts_success_rate = (alerts_passed / alerts_tests * 100) if alerts_tests > 0 else 0
    
    # Analyser les modules de shadow mode
    shadow_modules = [r for r in results if "shadow" in r["module"]]
    shadow_tests = sum(r["total"] for r in shadow_modules)
    shadow_passed = sum(r["passed"] for r in shadow_modules)
    shadow_success_rate = (shadow_passed / shadow_tests * 100) if shadow_tests > 0 else 0
    
    # Analyser les modules Docker
    docker_modules = [r for r in results if "docker" in r["module"]]
    docker_tests = sum(r["total"] for r in docker_modules)
    docker_passed = sum(r["passed"] for r in docker_modules)
    docker_success_rate = (docker_passed / docker_tests * 100) if docker_tests > 0 else 0
    
    # G√©n√©rer le rapport
    return {
        "timestamp": datetime.now(UTC).isoformat(),
        "step": "√âtape 10 - Couverture de tests ‚â• 70%",
        "summary": {
            "total_tests": total_tests,
            "total_passed": total_passed,
            "global_success_rate": global_success_rate,
            "target_met": global_success_rate >= 70,
            "rl_tests": rl_tests,
            "rl_passed": rl_passed,
            "rl_success_rate": rl_success_rate,
            "rl_target_met": rl_success_rate >= 85,
            "alerts_tests": alerts_tests,
            "alerts_passed": alerts_passed,
            "alerts_success_rate": alerts_success_rate,
            "shadow_tests": shadow_tests,
            "shadow_passed": shadow_passed,
            "shadow_success_rate": shadow_success_rate,
            "docker_tests": docker_tests,
            "docker_passed": docker_passed,
            "docker_success_rate": docker_success_rate
        },
        "test_results": results,
        "recommendations": generate_recommendations(results, global_success_rate, rl_success_rate)
    }
    

def generate_recommendations(results, global_success_rate, rl_success_rate):
    """G√©n√®re des recommandations bas√©es sur les r√©sultats."""
    recommendations = []
    
    # Recommandations globales
    if global_success_rate < 70:
        recommendations.append({
            "type": "critical",
            "message": f"Couverture globale insuffisante: {global_success_rate",
            "action": "Augmenter le nombre de tests et am√©liorer leur qualit√©"
        })
    else:
        recommendations.append({
            "type": "success",
            "message": f"Couverture globale atteinte: {global_success_rate",
            "action": "Maintenir la qualit√© des tests et surveiller la couverture"
        })
    
    # Recommandations pour les modules RL
    if rl_success_rate < 85:
        recommendations.append({
            "type": "warning",
            "message": f"Couverture RL insuffisante: {rl_success_rate",
            "action": "Am√©liorer les tests des modules RL pour atteindre 85%"
        })
    else:
        recommendations.append({
            "type": "success",
            "message": f"Couverture RL atteinte: {rl_success_rate",
            "action": "Maintenir la qualit√© des tests RL"
        })
    
    # Recommandations par module
    failed_modules = [r for r in results if r["status"] == "failed"]
    if failed_modules:
        recommendations.append({
            "type": "critical",
            "message": f"Modules avec tests √©chou√©s: {len(failed_modules)}",
            "action": "Corriger les tests √©chou√©s et v√©rifier l'impl√©mentation"
        })
    
    partial_modules = [r for r in results if r["status"] == "partial"]
    if partial_modules:
        recommendations.append({
            "type": "warning",
            "message": f"Modules avec tests partiels: {len(partial_modules)}",
            "action": "Am√©liorer les tests pour atteindre 100% de succ√®s"
        })
    
    error_modules = [r for r in results if r["status"] == "error"]
    if error_modules:
        recommendations.append({
            "type": "critical",
            "message": f"Modules avec erreurs: {len(error_modules)}",
            "action": "Corriger les erreurs d'ex√©cution des tests"
        })
    
    return recommendations

def save_report(report, filename="step10_final_coverage_report.json"):
    """Sauvegarde le rapport dans un fichier JSON."""
    report_path = Path(__file__).parent / filename
    
    with Path(report_path, "w", encoding="utf-8").open() as f:
        json.dump(report, f, indent=2, ensure_ascii=False)
    
    print("üìÑ Rapport sauvegard√©: {report_path}")
    return report_path

def print_final_summary(report):
    """Affiche un r√©sum√© final du rapport."""
    print("\n" + "="*60)
    print("üìä R√âSUM√â FINAL - √âTAPE 10 - COUVERTURE DE TESTS")
    print("="*60)
    
    summary = report["summary"]
    
    print("Tests totaux: {summary['total_tests']}")
    print("Tests r√©ussis: {summary['total_passed']}")
    print("Couverture globale: {summary['global_success_rate']")
    print("Objectif global (‚â•70%): {'‚úÖ' if summary['target_met'] else '‚ùå'}")
    
    print("\nTests RL: {summary['rl_tests']}")
    print("Tests RL r√©ussis: {summary['rl_passed']}")
    print("Couverture RL: {summary['rl_success_rate']")
    print("Objectif RL (‚â•85%): {'‚úÖ' if summary['rl_target_met'] else '‚ùå'}")
    
    print("\nTests Alertes: {summary['alerts_tests']}")
    print("Tests Alertes r√©ussis: {summary['alerts_passed']}")
    print("Couverture Alertes: {summary['alerts_success_rate']")
    
    print("\nTests Shadow Mode: {summary['shadow_tests']}")
    print("Tests Shadow Mode r√©ussis: {summary['shadow_passed']}")
    print("Couverture Shadow Mode: {summary['shadow_success_rate']")
    
    print("\nTests Docker: {summary['docker_tests']}")
    print("Tests Docker r√©ussis: {summary['docker_passed']}")
    print("Couverture Docker: {summary['docker_success_rate']")
    
    print("\nüìã R√©sultats par module:")
    for result in report["test_results"]:
        status_emoji = {
            "success": "‚úÖ",
            "partial": "‚ö†Ô∏è",
            "failed": "‚ùå",
            "error": "üí•"
        }.get(result["status"], "‚ùì")
        
        print("  {status_emoji} {result['module']}: {result['passed']}/{result['total']} ({result['success_rate']")
        if "error" in result:
            print("     Erreur: {result['error']}")
    
    print("\nüí° Recommandations:")
    for rec in report["recommendations"]:
        type_emoji = {
            "critical": "üö®",
            "warning": "‚ö†Ô∏è",
            "success": "‚úÖ",
            "info": "‚ÑπÔ∏è"
        }.get(rec["type"], "üìù")
        
        print("  {type_emoji} {rec['message']}")
        print("     Action: {rec['action']}")
    
    print("="*60)

def main():
    """Fonction principale."""
    print("üöÄ D√©marrage de l'ex√©cution finale des tests")
    print("üìÖ {datetime.now(UTC).strftime('%Y-%m-%d %H:%M:%S')} UTC")
    
    # Ex√©cuter tous les tests
    results, total_tests, total_passed = execute_all_tests()
    
    # G√©n√©rer le rapport de couverture
    report = generate_coverage_report(results, total_tests, total_passed)
    
    # Sauvegarder le rapport
    save_report(report)
    
    # Afficher le r√©sum√©
    print_final_summary(report)
    
    # D√©terminer le code de sortie
    if report["summary"]["target_met"] and report["summary"]["rl_target_met"]:
        print("\nüéâ √âtape 10 compl√©t√©e avec succ√®s!")
        print("‚úÖ Objectifs de couverture atteints:")
        print("   - Couverture globale: {report['summary']['global_success_rate']")
        print("   - Couverture RL: {report['summary']['rl_success_rate']")
        return 0
    print("\n‚ö†Ô∏è √âtape 10 partiellement compl√©t√©e")
    if not report["summary"]["target_met"]:
        print("‚ùå Couverture globale insuffisante: {report['summary']['global_success_rate']")
    if not report["summary"]["rl_target_met"]:
        print("‚ùå Couverture RL insuffisante: {report['summary']['rl_success_rate']")
    return 1

if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code)
