# yaml-language-server: disable
# ‚úÖ 2.11: Exemple de configuration Alertmanager pour PagerDuty
# 
# Usage:
#   1. Copier ce fichier vers alertmanager.yml
#   2. Remplacer <PAGERDUTY_INTEGRATION_KEY> par votre cl√© d'int√©gration PagerDuty
#   3. D√©ployer Alertmanager avec docker-compose ou Kubernetes
#
# Documentation: https://prometheus.io/docs/alerting/latest/configuration/

global:
  # Dur√©e avant de consid√©rer une alerte comme r√©solue
  resolve_timeout: 5m

# Configuration des routes d'alertes
route:
  # Route par d√©faut
  receiver: 'default'
  
  # Grouper les alertes par cluster et alertname
  group_by: ['cluster', 'alertname']
  
  # Grouper les alertes pendant 10 secondes avant d'envoyer
  group_wait: 10s
  
  # Attendre 10 secondes avant d'envoyer des alertes suppl√©mentaires au m√™me groupe
  group_interval: 10s
  
  # Renvoyer la m√™me alerte apr√®s 3 heures si non r√©solue
  repeat_interval: 3h
  
  # Routes sp√©cifiques pour PagerDuty (severity=critical)
  routes:
    # Route pour alertes critiques (PagerDuty)
    - match:
        severity: critical
        notification: pagerduty
      receiver: 'pagerduty-critical'
      continue: true  # Continuer √† √©valuer les routes suivantes
      
    # Route pour alertes warnings (PagerDuty)
    - match:
        severity: warning
        notification: pagerduty
      receiver: 'pagerduty-warning'
      continue: true
    
    # Route pour alertes Slack (toutes)
    - match:
        notification: slack
      receiver: 'slack'
      continue: false

# Receivers (destinations d'alertes)
receivers:
  # Receiver par d√©faut (Slack ou log)
  - name: 'default'
    slack_configs:
      - api_url: '${SLACK_WEBHOOK_URL}'
        channel: '#alerts'
        title: 'ATMR Alert: {{ .GroupLabels.alertname }}'
        text: '{{ range .Alerts }}{{ .Annotations.summary }}\n{{ .Annotations.description }}{{ end }}'
  
  # Receiver PagerDuty pour alertes critiques
  - name: 'pagerduty-critical'
    pagerduty_configs:
      - service_key: '<PAGERDUTY_INTEGRATION_KEY>'  # ‚ö†Ô∏è REMPLACER par votre cl√©
        description: '{{ .GroupLabels.alertname }}'
        severity: 'critical'
        details:
          summary: '{{ .CommonAnnotations.summary }}'
          description: '{{ .CommonAnnotations.description }}'
          runbook_url: '{{ .CommonAnnotations.runbook_url }}'
          component: '{{ .CommonLabels.component }}'
          environment: '{{ .CommonLabels.environment }}'
    
    # Fallback vers Slack si PagerDuty √©choue
    slack_configs:
      - api_url: '${SLACK_WEBHOOK_URL}'
        channel: '#alerts-critical'
        title: 'üö® Critical Alert: {{ .GroupLabels.alertname }}'
  
  # Receiver PagerDuty pour alertes warnings
  - name: 'pagerduty-warning'
    pagerduty_configs:
      - service_key: '<PAGERDUTY_INTEGRATION_KEY>'  # ‚ö†Ô∏è REMPLACER par votre cl√©
        description: '{{ .GroupLabels.alertname }}'
        severity: 'warning'
        details:
          summary: '{{ .CommonAnnotations.summary }}'
          description: '{{ .CommonAnnotations.description }}'
          runbook_url: '{{ .CommonAnnotations.runbook_url }}'
  
  # Receiver Slack pour alertes non-critiques
  - name: 'slack'
    slack_configs:
      - api_url: '${SLACK_WEBHOOK_URL}'
        channel: '#alerts'
        title: 'ATMR Alert: {{ .GroupLabels.alertname }}'
        text: |
          {{ range .Alerts }}
          *Severity:* {{ .Labels.severity }}
          *Component:* {{ .Labels.component }}
          *Summary:* {{ .Annotations.summary }}
          *Description:* {{ .Annotations.description }}
          {{ if .Annotations.runbook_url }}*Runbook:* {{ .Annotations.runbook_url }}{{ end }}
          {{ end }}

# Templates pour formater les messages
templates:
  - '/etc/alertmanager/templates/*.tmpl'

# Inhibition rules (supprimer alertes redondantes)
inhibit_rules:
  # Si une alerte critique est d√©clench√©e, supprimer les warnings pour le m√™me composant
  - source_match:
      severity: 'critical'
    target_match:
      severity: 'warning'
    equal: ['component', 'cluster']

