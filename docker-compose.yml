services:
  postgres:
    image: postgres:16-alpine
    environment:
      POSTGRES_DB: atmr
      POSTGRES_USER: atmr
      POSTGRES_PASSWORD: atmr
      TZ: Europe/Zurich
    ports: ["5432:5432"] # pratique en dev
    volumes:
      - pg_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U atmr -d atmr"]
      interval: 5s
      timeout: 3s
      retries: 10
    restart: unless-stopped
    # ✅ 3.6: Limits CPU/mémoire
    deploy:
      resources:
        limits:
          cpus: "1.0"
          memory: 1G
        reservations:
          cpus: "0.5"
          memory: 512M

  # ✅ 3.5: Reverse proxy nginx (optionnel, décommenter pour activer)
  # nginx:
  #   image: nginx:alpine
  #   ports:
  #     - "80:80"
  #   volumes:
  #     - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
  #   depends_on:
  #     - api
  #   restart: unless-stopped
  #   networks:
  #     - default

  api:
    build:
      context: ./backend
      dockerfile: Dockerfile
    # ✅ 3.5: Si nginx est activé, l'API n'a pas besoin d'exposer le port 5000 publiquement
    # expose:
    #   - "5000"
    healthcheck:
      test:
        [
          "CMD-SHELL",
          'python -c "import sys,urllib.request; r=urllib.request.urlopen(''http://127.0.0.1:5000/health'', timeout=3); sys.exit(0 if getattr(r,''status'',200)==200 else 1)"',
        ]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    command: >
      gunicorn wsgi:app
      --bind 0.0.0.0:5000
      --worker-class eventlet
      --workers ${GUNICORN_WORKERS:-2}
      --timeout 120
      --access-logfile -
      --error-logfile -
      --log-level debug
      --no-sendfile
    ports:
      - "5000:5000"
    env_file:
      - backend/.env
    environment:
      - PYTHONPATH=/app
      - GUNICORN_WORKERS=2
      - DATABASE_URL=postgresql+psycopg://atmr:atmr@postgres:5432/atmr
      - SOCKETIO_ASYNC_MODE=${SOCKETIO_ASYNC_MODE:-eventlet}
      - SIO_DISABLE_UPGRADES=false
      - REDIS_URL=${REDIS_URL:-redis://redis:6379/0}
      - CELERY_BROKER_URL=${CELERY_BROKER_URL:-redis://redis:6379/0}
      - CELERY_RESULT_BACKEND=${CELERY_RESULT_BACKEND:-redis://redis:6379/0}
      - CELERY_TIMEZONE=${CELERY_TIMEZONE:-Europe/Zurich}
      - DISPATCH_AUTORUN_INTERVAL_SEC=${DISPATCH_AUTORUN_INTERVAL_SEC:-300}
      - DISPATCH_AUTORUN_ENABLED=${DISPATCH_AUTORUN_ENABLED:-true}
      - UD_OSRM_URL=${UD_OSRM_URL:-http://osrm:5000}
      - SOCKETIO_CORS_ORIGINS=${SOCKETIO_CORS_ORIGINS:-http://localhost:3000,http://127.0.0.1:3000}
      - FLASK_CONFIG=${FLASK_CONFIG:-development}
      - FLASK_ENV=${FLASK_ENV:-development}
      - TZ=Europe/Zurich
      - PDF_BASE_URL=${PDF_BASE_URL:-http://localhost:5000}
      - UPLOADS_PUBLIC_BASE=${UPLOADS_PUBLIC_BASE:-/uploads}
      - API_DOCS=${API_DOCS:-off}
      - API_LEGACY_ENABLED=${API_LEGACY_ENABLED:-false}
      # ✅ D3: Variables de chaos (NE JAMAIS activer en production)
      - CHAOS_ENABLED=${CHAOS_ENABLED:-false}
      - CHAOS_OSRM_DOWN=${CHAOS_OSRM_DOWN:-false}
      - CHAOS_DB_READ_ONLY=${CHAOS_DB_READ_ONLY:-false}
    volumes:
      - ./backend:/app
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_started
      osrm:
        condition: service_started
    restart: unless-stopped
    # ✅ 3.6: Limits CPU/mémoire pour API
    deploy:
      resources:
        limits:
          cpus: "3.0"
          memory: 6G
        reservations:
          cpus: "1.5"
          memory: 3G

  celery-worker:
    build:
      context: ./backend
    healthcheck:
      test:
        [
          "CMD-SHELL",
          "celery -A celery_app:celery inspect ping -d celery@$$HOSTNAME -t 5 || exit 1",
        ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    command:
      [
        "celery",
        "-A",
        "celery_app:celery",
        "worker",
        "-l",
        "info",
        "--concurrency",
        "4",
        "--max-tasks-per-child",
        "100",
      ]
    env_file:
      - backend/.env
    environment:
      - DATABASE_URL=postgresql+psycopg://atmr:atmr@postgres:5432/atmr
      - PYTHONPATH=/app
      - REDIS_URL=${REDIS_URL:-redis://redis:6379/0}
      - CELERY_BROKER_URL=${CELERY_BROKER_URL:-redis://redis:6379/0}
      - CELERY_RESULT_BACKEND=${CELERY_RESULT_BACKEND:-redis://redis:6379/0}
      - CELERY_TIMEZONE=${CELERY_TIMEZONE:-Europe/Zurich}
      - DISPATCH_AUTORUN_INTERVAL_SEC=${DISPATCH_AUTORUN_INTERVAL_SEC:-300}
      - DISPATCH_AUTORUN_ENABLED=${DISPATCH_AUTORUN_ENABLED:-true}
      - UD_OSRM_URL=${UD_OSRM_URL:-http://osrm:5000}
      - FLASK_CONFIG=${FLASK_CONFIG:-development}
      - FLASK_ENV=${FLASK_ENV:-development}
      - PDF_BASE_URL=${PDF_BASE_URL:-http://localhost:5000}
      - TZ=Europe/Zurich
    volumes:
      - ./backend:/app
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_started
      api:
        condition: service_healthy
    restart: unless-stopped
    # ✅ 3.6: Limits CPU/mémoire pour Celery Worker
    deploy:
      resources:
        limits:
          cpus: "1.0"
          memory: 1G
        reservations:
          cpus: "0.5"
          memory: 512M

  celery-beat:
    build:
      context: ./backend
    healthcheck:
      test:
        [
          "CMD-SHELL",
          "test -f /app/celerybeat-schedule.dat && echo 'ok' || exit 1",
        ]
      interval: 60s
      timeout: 5s
      retries: 3
      start_period: 30s
    command:
      [
        "celery",
        "-A",
        "celery_app:celery",
        "beat",
        "-l",
        "info",
        "-S",
        "celery.beat.PersistentScheduler",
        "-s",
        "/app/celerybeat-schedule",
      ]
    env_file:
      - backend/.env
    environment:
      - DATABASE_URL=postgresql+psycopg://atmr:atmr@postgres:5432/atmr
      - PYTHONPATH=/app
      - REDIS_URL=${REDIS_URL:-redis://redis:6379/0}
      - CELERY_BROKER_URL=${CELERY_BROKER_URL:-redis://redis:6379/0}
      - CELERY_RESULT_BACKEND=${CELERY_RESULT_BACKEND:-redis://redis:6379/0}
      - CELERY_TIMEZONE=${CELERY_TIMEZONE:-Europe/Zurich}
      - DISPATCH_AUTORUN_INTERVAL_SEC=${DISPATCH_AUTORUN_INTERVAL_SEC:-300}
      - DISPATCH_AUTORUN_ENABLED=${DISPATCH_AUTORUN_ENABLED:-true}
      - FLASK_CONFIG=${FLASK_CONFIG:-development}
      - FLASK_ENV=${FLASK_ENV:-development}
      - PDF_BASE_URL=${PDF_BASE_URL:-http://localhost:5000}
    volumes:
      - ./backend:/app
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_started
      api:
        condition: service_healthy
    restart: unless-stopped
    # ✅ 3.6: Limits CPU/mémoire pour Celery Beat
    deploy:
      resources:
        limits:
          cpus: "0.25"
          memory: 256M
        reservations:
          cpus: "0.1"
          memory: 128M

  flower:
    build:
      context: ./backend
    healthcheck:
      test:
        [
          "CMD-SHELL",
          'python -c "import urllib.request; urllib.request.urlopen(''http://localhost:5555'', timeout=3)" || exit 1',
        ]
      interval: 30s
      timeout: 5s
      retries: 3
      start_period: 20s
    command: ["celery", "-A", "celery_app:celery", "flower", "--port=5555"]

    ports:
      - "5555:5555"
    env_file:
      - backend/.env
    environment:
      - DATABASE_URL=postgresql+psycopg://atmr:atmr@postgres:5432/atmr
      - PYTHONPATH=/app
      - REDIS_URL=${REDIS_URL:-redis://redis:6379/0}
    volumes:
      - ./backend:/app
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_started
      celery-worker:
        condition: service_started
    restart: unless-stopped
    # ✅ 3.6: Limits CPU/mémoire pour Flower
    deploy:
      resources:
        limits:
          cpus: "0.25"
          memory: 256M
        reservations:
          cpus: "0.1"
          memory: 128M

  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis-data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 5s
      timeout: 3s
      retries: 5
    command: redis-server --appendonly yes
    restart: unless-stopped
    # ✅ 3.6: Limits CPU/mémoire pour Redis
    deploy:
      resources:
        limits:
          cpus: "0.5"
          memory: 512M
        reservations:
          cpus: "0.25"
          memory: 256M

  osrm:
    image: osrm/osrm-backend:latest
    volumes:
      - ./osrm/data:/data
    # Note: Pas de healthcheck natif (image minimale sans wget/curl)
    # OSRM est testé via fallback haversine côté backend si indisponible
    command: osrm-routed --algorithm mld /data/switzerland-latest.osrm
    restart: unless-stopped
    # ✅ 3.6: Limits CPU/mémoire pour OSRM
    deploy:
      resources:
        limits:
          cpus: "1.0"
          memory: 2G
        reservations:
          cpus: "0.5"
          memory: 1G

  prometheus:
    image: prom/prometheus:latest
    container_name: atmr-prometheus
    command:
      - "--config.file=/etc/prometheus/prometheus.yml"
      - "--storage.tsdb.path=/prometheus"
      - "--web.console.libraries=/usr/share/prometheus/console_libraries"
      - "--web.console.templates=/usr/share/prometheus/consoles"
      - "--storage.tsdb.retention.time=30d"
      - "--web.enable-lifecycle"
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus:/etc/prometheus:ro
      - prometheus-data:/prometheus
    healthcheck:
      test:
        [
          "CMD",
          "wget",
          "--quiet",
          "--tries=1",
          "--spider",
          "http://localhost:9090/-/healthy",
        ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    depends_on:
      api:
        condition: service_healthy
    restart: unless-stopped
    # ✅ 3.6: Limits CPU/mémoire pour Prometheus
    deploy:
      resources:
        limits:
          cpus: "1.0"
          memory: 2G
        reservations:
          cpus: "0.5"
          memory: 1G

  grafana:
    image: grafana/grafana:latest
    container_name: atmr-grafana
    ports:
      - "3001:3000"
    environment:
      - GF_SECURITY_ADMIN_USER=${GRAFANA_ADMIN_USER:-admin}
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_ADMIN_PASSWORD:-admin}
      - GF_USERS_ALLOW_SIGN_UP=false
      - GF_SERVER_ROOT_URL=http://localhost:3001
      - GF_INSTALL_PLUGINS=
    volumes:
      - grafana-data:/var/lib/grafana
      - ./grafana/provisioning:/etc/grafana/provisioning:ro
      - ./grafana/dashboards:/var/lib/grafana/dashboards:ro
    healthcheck:
      test:
        [
          "CMD",
          "wget",
          "--quiet",
          "--tries=1",
          "--spider",
          "http://localhost:3000/api/health",
        ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 20s
    depends_on:
      prometheus:
        condition: service_healthy
    restart: unless-stopped
    # ✅ 3.6: Limits CPU/mémoire pour Grafana
    deploy:
      resources:
        limits:
          cpus: "0.5"
          memory: 512M
        reservations:
          cpus: "0.25"
          memory: 256M

volumes:
  pg_data:
  redis-data:
  prometheus-data:
  grafana-data:
